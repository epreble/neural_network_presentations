{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sectionTop'></a>\n",
    "# Image Classification with Tensorflow/Inception\n",
    "\n",
    "[1. Installation (Mac)](#section1)<br>\n",
    "&nbsp;&nbsp;&nbsp;A. Tensorflow<br>\n",
    "&nbsp;&nbsp;&nbsp;B. Inception v3<br>\n",
    "[2. Prep of images/data for tensorflow](#section2)<br>\n",
    "&nbsp;&nbsp;&nbsp;A. Flowers Data (Google \"Tensorflow for Poets\" Demo)<br>\n",
    "[3. Retraining the model](#section3)<br>\n",
    "[4. Demo Test Results](#section4)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 1. Installation (Mac)\n",
    "I use Miniconda for my python environments. These commands are done from command line (Mac Terminal).<br>\n",
    "NOTE:\n",
    "- Donâ€™t change the order of these commands! (There are some weird pip bugs right now)\n",
    "- You must use Python 3.6 (tensorflow does not work on python 3.7 as of 10/6/2018)\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "conda create -n iaa python=3.6\n",
    "<br>source activate iaa\n",
    "<br>pip install --upgrade pip\n",
    "<br>pip install --upgrade \"tensorflow==1.7.*\"\n",
    "<br>conda install jupyter\n",
    "</div>\n",
    "\n",
    "To check if tensorflow is working - From terminal, start a python shell:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "python</div>\n",
    "\n",
    "Run this code snippet, which prints \"Hello, TensorFlow!\" if everything is ok\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "import tensorflow as tf\n",
    "<br>hello = tf.constant('Hello, TensorFlow!')\n",
    "<br>sess = tf.Session()\n",
    "<br>print(sess.run(hello))</div>\n",
    "\n",
    "Type exit() to exit the shell\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "exit()\n",
    "</div>\n",
    "\n",
    "Copy Inception v3 architecture and pre-trained library\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "git clone https://github.com/googlecodelabs/tensorflow-for-poets-2\n",
    "<br>cd tensorflow-for-poets-2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 2. Prep of images/data for tensorflow\n",
    "\n",
    "Tensorflow appears to prefer JPGs. PNG can supposedly work (as it does in Tensorbox demo), but I haven't gotten it working for this basic classification example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowers Data (Google \"Tensorflow for Poets\" Demo):\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "curl http://download.tensorflow.org/example_images/flower_photos.tgz \\\n",
    "<br>tar xz -C tf_files\n",
    "<br>ls tf_files/flower_photos\n",
    "</div>\n",
    "\n",
    "Should list 5 directories, which have ~3600 images in total:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "daisy/\n",
    "<br>dandelion/\n",
    "<br>roses/\n",
    "<br>sunflowers/\n",
    "<br>tulips/\n",
    "<br>LICENSE.txt\n",
    "</div>\n",
    "\n",
    "Move a few images of each flower out of training location to use for testing later:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "mkdir test_images\n",
    "<br>mkdir test_images/flower_photos\n",
    "<br>mv ./tf_files/flower_photos/roses/102501987_3cdb8e5394_n.jpg ./test_images/flower_photos/rose1.jpg\n",
    "<br>mv ./tf_files/flower_photos/roses/6231418894_7946a7712b_n.jpg ./test_images/flower_photos/rose2.jpg\n",
    "<br>mv ./tf_files/flower_photos/roses/21522100663_455b77a90c_n.jpg ./test_images/flower_photos/rose3.jpg\n",
    "<br>mv ./tf_files/flower_photos/daisy/5547758_eea9edfd54_n.jpg ./test_images/flower_photos/daisy1.jpg\n",
    "<br>mv ./tf_files/flower_photos/daisy/2713919471_301fcc941f.jpg ./test_images/flower_photos/daisy2.jpg\n",
    "<br>mv ./tf_files/flower_photos/daisy/7630520686_e3a61ac763.jpg ./test_images/flower_photos/daisy3.jpg\n",
    "<br>mv ./tf_files/flower_photos/dandelion/8475758_4c861ab268_m.jpg ./test_images/flower_photos/dandelion1.jpg\n",
    "<br>mv ./tf_files/flower_photos/dandelion/4632761610_768360d425.jpg ./test_images/flower_photos/dandelion2.jpg\n",
    "<br>mv ./tf_files/flower_photos/dandelion/15644450971_6a28298454_n.jpg ./test_images/flower_photos/dandelion3.jpg\n",
    "<br>mv ./tf_files/flower_photos/sunflowers/27465811_9477c9d044.jpg ./test_images/flower_photos/sunflowers1.jpg\n",
    "<br>mv ./tf_files/flower_photos/sunflowers/5020805135_1219d7523d.jpg ./test_images/flower_photos/sunflowers2.jpg\n",
    "<br>mv ./tf_files/flower_photos/sunflowers/9056495873_66e351b17c_n.jpg ./test_images/flower_photos/sunflowers3.jpg\n",
    "<br>mv ./tf_files/flower_photos/tulips/11746367_d23a35b085_n.jpg ./test_images/flower_photos/tulips1.jpg\n",
    "<br>mv ./tf_files/flower_photos/tulips/5674695558_61397a1584.jpg ./test_images/flower_photos/tulips2.jpg\n",
    "<br>mv ./tf_files/flower_photos/tulips/13923539227_bdab038dc8.jpg ./test_images/flower_photos/tulips3.jpg\n",
    "</div>\n",
    "\n",
    "<center>Example Rose Image</center> | <center>Example Tulip Image</center>\n",
    "- | - \n",
    "<img src=\"./test_images/flower_photos/rose1.jpg\" alt=\"Rose\" style=\"width: 400px;\"/> | <img src=\"./test_images/flower_photos/tulips1.jpg\" alt=\"Tulip\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 3. Retraining the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In terminal window, startup tensorflow dashboard to monitor the training process\n",
    "(if using miniconda environments as specified above, be sure \"iaa\" environment is running. \"source activate iaa\"\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "tensorboard --logdir tf_files/training_summaries &\n",
    "</div>\n",
    "\n",
    "Script output will say the tensorboard is at: http://yourcomputername:6006, but I need to use http://localhost:6006 instead\n",
    "\n",
    "###### In another terminal window, run the retraining scripts\n",
    "(if using miniconda environments as specified above, be sure \"iaa\" environment is running. \"source activate iaa\"\n",
    "<br>Run the python retraining script help, confirms that the retrain.py is functioning ok\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "python -m scripts.retrain -h\n",
    "</div>\n",
    "\n",
    "<br>This script handles 3 things:\n",
    "- Download model architecture (only happens once for that model)\n",
    "- Create bottleneck files for each training image (only happens the first time an image is trained on a model)\n",
    "- Retrain model (n training steps executed, 4000 is default)\n",
    "\n",
    "<br>There are also bugs in the label_image.py file:\n",
    "Change:\n",
    "```    \n",
    "  input_height = 299\n",
    "  input_width = 299\n",
    "  input_mean = 0\n",
    "  input_std = 255\n",
    "  input_layer = \"Mul\"\n",
    "```\n",
    "  \n",
    "to:\n",
    "```\n",
    "  input_height = 224\n",
    "  input_width = 224\n",
    "  input_mean = 128\n",
    "  input_std = 128\n",
    "  input_layer = \"input\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Flowers Data (Google \"Tensorflow for Poets\" Demo):\n",
    "ImageNet can be retrained using the Inception_v3 architecture on the Flowers dataset with the below command\n",
    "<br> 2 mins to make bottlenecks the first time\n",
    "<br> 3 mins to train 4000 steps (claims 88.6% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "IMAGE_SIZE=224\n",
    "ARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\"\n",
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --model_dir=tf_files/models/\"${ARCHITECTURE}\" \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=tf_files/flower_photos```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='section4'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 4. Demo Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model reported 88.6% accuracy after 4000 step training.\n",
    "Some actual results below (14/15 correct):\n",
    "\n",
    "```python -m scripts.label_image \\\n",
    "    --graph=tf_files/retrained_graph.pb  \\\n",
    "    --labels=tf_files/retrained_labels.txt  \\\n",
    "    --image=test_images/flower_photos/rose1.jpg```\n",
    "    \n",
    "    \n",
    "<center></center> | <center></center> | <center></center>\n",
    "- | - | -\n",
    "<center>**Rose 1<br>roses 1.000**<br>tulips 0.000<br>sunflowers 0.000<br>daisy 0.000<br>dandelion 0.000</center> | <center>**Rose 2<br>roses 0.964**<br>tulips 0.018<br>sunflowers 0.000<br>daisy 0.000<br>dandelion 0.018</center> | <center>**Rose 3<br>roses 0.999**<br>tulips 0.001<br>sunflowers 0.000<br>daisy 0.000<br>dandelion 0.000</center>\n",
    "<img src=\"./test_images/flower_photos/rose1.jpg\"/> | <img src=\"./test_images/flower_photos/rose2.jpg\"/> | <img src=\"./test_images/flower_photos/rose3.jpg\"/>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center>**Tulip 1<br>tulips 0.998**<br>roses 0.001<br>dandelion 0.001<br>daisy 0.000<br>sunflowers 0.000</center> | <center>**Tulip 2<br>tulips 1.000**<br>sunflowers 0.000<br>daisy 0.000<br>dandelion 0.000<br>roses 0.000</center> | <center>**Tulip 3<br>tulips 1.000**<br>dandelion 0.000<br>sunflowers 0.000<br>roses 0.000<br>daisy 0.000</center>\n",
    "<img src=\"./test_images/flower_photos/tulips1.jpg\"/> | <img src=\"./test_images/flower_photos/tulips2.jpg\"/> | <img src=\"./test_images/flower_photos/tulips3.jpg\"/>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center>**Dandelion 1<br><font color=\"FF0000\">sunflowers 1.000**</font><br>dandelion 0.000<br>daisy 0.000<br>tulips 0.000<br>roses 0.000</center> | <center>**Dandelion 2<br>dandelion 1.000**<br>sunflowers 0.000<br>tulips 0.000<br>roses 0.000<br>daisy 0.000</center> | <center>**Dandelion 3**<br>**dandelion 1.000**<br>sunflowers 0.000<br>tulips 0.000<br>daisy 0.000<br>roses 0.000</center>\n",
    "<img src=\"./test_images/flower_photos/dandelion1.jpg\"/> | <img src=\"./test_images/flower_photos/dandelion2.jpg\"/> | <img src=\"./test_images/flower_photos/dandelion3.jpg\"/>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center>**Daisy 1<br>daisy 0.992**<br>dandelion 0.007<br>sunflowers 0.000<br>tulips 0.000<br>roses 0.000</center> | <center>**Daisy 2<br>daisy 1.000**<br>sunflowers 0.000<br>dandelion 0.000<br>roses 0.000<br>tulips 0.000</center> | <center>**Daisy 3<br>daisy 0.999**<br>sunflowers 0.000<br>dandelion 0.000<br>tulips 0.001<br>roses 0.000</center>\n",
    "<img src=\"./test_images/flower_photos/daisy1.jpg\"/> | <img src=\"./test_images/flower_photos/daisy2.jpg\"/> | <img src=\"./test_images/flower_photos/daisy3.jpg\"/>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center></center> | <center></center> | <center></center>\n",
    "<center>**Sunflower 1<br>sunflowers 0.998**<br>dandelion 0.000<br>tulips 0.002<br>daisy 0.000<br>roses 0.000</center> | <center>**Sunflower 2<br>sunflowers 0.997**<br>dandelion 0.000<br>daisy 0.003<br>tulips 0.000<br>roses 0.000</center> | <center>**Sunflower 3<br>sunflowers 0.964**<br>tulips 0.032<br>dandelion 0.001<br>roses 0.003<br>daisy 0.000</center>\n",
    "<img src=\"./test_images/flower_photos/sunflowers1.jpg\"/> | <img src=\"./test_images/flower_photos/sunflowers2.jpg\"/> | <img src=\"./test_images/flower_photos/sunflowers3.jpg\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
